{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "from random import randint\n",
    "import scipy.signal\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import sqrt\n",
    "import xarray as xr\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "import math\n",
    "import pylab\n",
    "import operator\n",
    "from sklearn import neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn import metrics, preprocessing \n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.2)\n",
    "import xlwt\n",
    "from xlrd import open_workbook\n",
    "from openpyxl import load_workbook\n",
    "import xlrd\n",
    "import xlutils\n",
    "from xlutils.copy import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimesion of dataset:  (4, 10, 15000)\n",
      "Dimesion of dataset_add:  (4, 6, 15000)\n",
      "'''''Import successfully'''''\n",
      "Dimesion of datasets is:  (4, 16, 15000)\n"
     ]
    }
   ],
   "source": [
    "#import datasets #Ignoring Condition 1 index0\n",
    "X_im = np.load('Dataset_10_subjs_60secs_5conds_filrange6and25Hz.npy')[1:,:,:]\n",
    "X_im_add = np.load('Dataset_Additional_6_subjs_60secs_5conds_filrange6and25Hz.npy')[1:,:,:]\n",
    "print(\"Dimesion of dataset: \", X_im.shape)\n",
    "print(\"Dimesion of dataset_add: \", X_im_add.shape)\n",
    "print(\"'''''Import successfully'''''\")\n",
    "\n",
    "#Combine datasets\n",
    "X_import = np.concatenate((X_im, X_im_add), axis=1)\n",
    "print(\"Dimesion of datasets is: \", X_import.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characteristic of the data\n",
    "num_cond = int(X_import.shape[0]) \n",
    "person_num = int(X_import.shape[1])\n",
    "smp_freq = 250  # 250 Hz\n",
    "win_len = 3 # 3s  Using sliding window size 3 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window by using size of 3 seconds\n",
    "len_data = int(X_import.shape[2]/smp_freq) #Find new length data\n",
    "number_window = int(len_data-win_len+1) \n",
    "\n",
    "X_windowed = np.ones((num_cond, person_num, number_window, win_len*smp_freq))\n",
    "\n",
    "for cond in range(num_cond):\n",
    "    for p in range(person_num): #number of prople\n",
    "        for idx in range(number_window): #num of slice\n",
    "            X_windowed[cond, p, idx, :] = X_import[cond, p, idx*smp_freq:(idx+ win_len) * smp_freq]\n",
    "\n",
    "print(\"Dimension of data after used sliding window:\", X_windowed.shape)\n",
    "print(\"'''''Applied Sliding Window Successfully'''''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define window length (4 seconds)\n",
    "# win = 3 * smp_freq\n",
    "# freqs, psd = signal.welch(X_windowed[0,0,3,:], smp_freq, nperseg=win)\n",
    "# freqs2, psd2 = signal.welch(X_windowed[1,0,0,:], smp_freq, nperseg=win)\n",
    "# freqs3, psd3 = signal.welch(X_windowed[2,0,0,:], smp_freq, nperseg=win)\n",
    "# # Plot the power spectrum\n",
    "# sns.set(font_scale=1.2, style='white')\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# plt.plot(freqs, psd, color='k', lw=2)\n",
    "# # plt.plot(freqs2, psd2, color='r', lw=2)\n",
    "# plt.plot(freqs3, psd3, color='b', lw=2)\n",
    "# plt.xlabel('Frequency (Hz)')\n",
    "# plt.ylabel('Power spectral density (V^2 / Hz)')\n",
    "# plt.ylim([0, psd.max() * 1.1])\n",
    "# plt.title(\"Welch's periodogram\")\n",
    "# plt.xlim([0, 26])\n",
    "# sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CCA for frequency recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition = 1       #1-4 ignore con0\n",
    "PI = np.pi\n",
    "sampling_frequency = smp_freq\n",
    "candidate_frequency = [7.5, 10]\n",
    "reference_signal_phase = 0\n",
    "correct_frequency = 7.5\n",
    "num_harmonic = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Reference Frequency\n",
    "sin = lambda f, h, t, p: np.sin(2*PI*f*h*t + p)\n",
    "cos = lambda f, h, t, p: np.cos(2*PI*f*h*t + p)\n",
    "ref_wave = lambda f, h, t, p: [sin(f, h, t, p), cos(f, h, t, p)]\n",
    "\n",
    "def generate_reference_signal_at_time(f, t, max_harmonic, phase):\n",
    "    values = []\n",
    "    for h in range(1, max_harmonic + 1):\n",
    "        values += ref_wave(f, h, t, phase)\n",
    "    return values\n",
    "\n",
    "def generate_reference_signal(frequency, sampling_frequency, total_time, max_harmonic, phase):\n",
    "    ref_signal = []\n",
    "    num_time_step = total_time * sampling_frequency\n",
    "    for step in range(num_time_step):\n",
    "        time = step * 1/sampling_frequency\n",
    "        ref_signal_at_t = generate_reference_signal_at_time(frequency, time, max_harmonic, phase)\n",
    "        ref_signal.append(ref_signal_at_t)\n",
    "    return ref_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for Maximum CCA from two multidimensional signal\n",
    "def find_maximum_canonical_correlations(X, Y):\n",
    "    if X.shape[0] == Y.shape[0]:\n",
    "        N = X.shape[0]\n",
    "    else:\n",
    "        print('time frame is not equal')\n",
    "        return None\n",
    "    C_xx = 1/N * (X.T @ X)\n",
    "    C_yy = 1/N * (Y.T @ Y)\n",
    "    C_xy = 1/N * (X.T @ Y)\n",
    "    C_yx = 1/N * (Y.T @ X)\n",
    "    C_xx_inv = np.linalg.pinv(C_xx)\n",
    "    C_yy_inv = np.linalg.pinv(C_yy)\n",
    "    eig_values, eig_vectors = scipy.linalg.eig(C_yy_inv @ C_yx @ C_xx_inv @ C_xy)\n",
    "    sqrt_eig_values = np.sqrt(eig_values)\n",
    "    return max(sqrt_eig_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Reference Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Generate reference signal from candidate frequency upto 6th harmonic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_signal = {}\n",
    "for frequency in candidate_frequency:\n",
    "    signal = generate_reference_signal(\n",
    "            frequency=frequency,\n",
    "            sampling_frequency=smp_freq,\n",
    "            total_time=win_len ,\n",
    "            max_harmonic=num_harmonic,\n",
    "            phase=reference_signal_phase\n",
    "    )\n",
    "    ref_signal[frequency] = pd.DataFrame(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBCCA constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Band Pass Filter Constant\n",
    "# filter_order = 2\n",
    "# subband_width = 8\n",
    "# # add pad frequency to both and high\n",
    "# PASSBAND_RIPPLE = 0.5\n",
    "# padding_frequency = 2\n",
    "# num_subband = 7\n",
    "# # from paper\n",
    "# subband_weight_a = 1.25\n",
    "# subband_weight_b = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band Pass Filter Constant\n",
    "filter_order = 2\n",
    "subband_width = 8\n",
    "# add pad frequency to both and high\n",
    "PASSBAND_RIPPLE = 100 #0.5 is default\n",
    "padding_frequency = 2\n",
    "num_subband = 8\n",
    "# from paper\n",
    "subband_weight_a = 1.25\n",
    "subband_weight_b = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band Filter Input Signal\n",
    "def filter_signal_verson2(data, low_cutoff_frequency, high_cutoff_frequency):\n",
    "    low = low_cutoff_frequency\n",
    "    high = high_cutoff_frequency\n",
    "    rp = PASSBAND_RIPPLE\n",
    "    # use Chebyshev Type 1 Filter as described in the Filter Bank paper\n",
    "    # Ref: https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.signal.cheby1.html\n",
    "    sos = scipy.signal.cheby1(filter_order, rp, [low, high], btype='bandpass', analog=False, fs=sampling_frequency, output='sos')\n",
    "    # filtfilt has some issued with number precision so we will use\n",
    "    # SOS (Second-order (biquadratic) IIR digital filtering)\n",
    "    # view Limitations Section in https://www.mathworks.com/help/signal/ref/cheby1.html\n",
    "    filtered_signal = scipy.signal.sosfiltfilt(sos, data, axis=0)\n",
    "    return filtered_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subband_cutoff(subband_type, start_frequency, subband_width, padding_frequency, num_subband):\n",
    "    # M1\n",
    "    if subband_type == 'M1':\n",
    "        return [\n",
    "            (start_frequency + subband_width * i - padding_frequency,\n",
    "             start_frequency + subband_width * (i + 1) + padding_frequency)\n",
    "            for i in range(1,  num_subband + 1)\n",
    "        ]\n",
    "    if subband_type == 'M2':\n",
    "        last_cutoff = start_frequency + subband_width * (num_subband + 1) + padding_frequency\n",
    "        return [\n",
    "            (start_frequency + subband_width * i - padding_frequency,\n",
    "             min(start_frequency + 2 * subband_width * i + padding_frequency, last_cutoff))\n",
    "            for i in range(1,  num_subband + 1)\n",
    "        ]\n",
    "    # M3\n",
    "    if subband_type == 'M3':\n",
    "        last_cutoff = start_frequency + subband_width * (num_subband + 1) + padding_frequency\n",
    "        return [\n",
    "            (start_frequency + subband_width * i - padding_frequency,\n",
    "             last_cutoff)\n",
    "            for i in range(1, num_subband + 1)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub band signal weight for FBCCA\n",
    "# optimal a, b from the paper\n",
    "def subband_weight(n, a=1.25, b=0.25):\n",
    "    return n ** (-a) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subband_weight_vector(num_subband, a=1.25, b=0.25):\n",
    "    return np.array([subband_weight(n+1, a, b) for n in range(num_subband)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBCCA main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subbands = generate_subband_cutoff('M3', 0, subband_width, padding_frequency, num_subband)\n",
    "display(subbands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_fbcca(data, ref_signal, a, b):\n",
    "    filtered_signal = {}\n",
    "    input_signal = data\n",
    "    for subband in subbands:\n",
    "        filtered_signal[f\"{subband[0]}_{subband[1]}\"] = \\\n",
    "            pd.DataFrame(filter_signal_verson2(input_signal, subband[0], subband[1]))\n",
    "    max_cca = {}\n",
    "\n",
    "    for subband_key in filtered_signal.keys():\n",
    "        for ref_signal_key in ref_signal.keys():\n",
    "            value = find_maximum_canonical_correlations(filtered_signal[subband_key], ref_signal[ref_signal_key])\n",
    "            if ref_signal_key not in max_cca:\n",
    "                max_cca[ref_signal_key] = []\n",
    "            if value.imag == 0.0:\n",
    "                value = value.real\n",
    "            if ref_signal_key not in max_cca:\n",
    "                max_cca[ref_signal_key] = []\n",
    "            max_cca[ref_signal_key].append(value)\n",
    "    rho = {}\n",
    "    for key in max_cca.keys():\n",
    "        rho[key] = np.array(max_cca[key])\n",
    "    weight = get_subband_weight_vector(num_subband, a, b)\n",
    "    result = {}\n",
    "    for key in rho.keys():\n",
    "        result[key] = np.sum(weight * rho[key] ** 2)\n",
    "    result[\"result\"] = max(result.items(), key=operator.itemgetter(1))[0]  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_extracted = np.zeros((X_windowed.shape[0], X_windowed.shape[1], X_windowed.shape[2], X_windowed.shape[3])) #11 freq range is interesting\n",
    "X_tr_FFT_extracted = np.zeros((X_windowed.shape[0], X_windowed.shape[1], X_windowed.shape[2]))\n",
    "CCA_result = np.zeros((X_windowed.shape[0], X_windowed.shape[1], X_windowed.shape[2]))\n",
    "\n",
    "for num_con in range(X_windowed.shape[0]):\n",
    "    for per_idx in range(X_windowed.shape[1]):\n",
    "        for num_win in range(X_windowed.shape[2]):\n",
    "            FBCCA_classifier_result = classify_fbcca(X_windowed[num_con, per_idx, num_win], ref_signal,subband_weight_a, subband_weight_b)\n",
    "            freq_res = FBCCA_classifier_result['result']\n",
    "            if freq_res == 7.5:\n",
    "                #CCA performing\n",
    "                CCA_result[num_con, per_idx, num_win] = 7.5\n",
    "                \n",
    "                #Make banpass_filter\n",
    "                data_used = X_windowed[num_con, per_idx, num_win, :]\n",
    "                data_filtered = filter_signal_verson2(data_used, 7, 8)\n",
    "                X_tr_extracted[num_con, per_idx, num_win, :] = data_filtered\n",
    "                \n",
    "                #PSD extraction\n",
    "                win_point = win_len * smp_freq\n",
    "                freqs, psd = scipy.signal.welch(data_used, smp_freq, nperseg = win_point)\n",
    "                magnitude = np.abs(psd)[np.where((freqs >= 7.6) & (freqs <=7.7))]\n",
    "                X_tr_FFT_extracted[num_con, per_idx, num_win] = magnitude\n",
    "                \n",
    "            else:\n",
    "                #CCA performing\n",
    "                CCA_result[num_con, per_idx, num_win] = 10\n",
    "                \n",
    "                #Make banpass_filter\n",
    "                data_used = X_windowed[num_con, per_idx, num_win, :]\n",
    "                data_filtered = filter_signal_verson2(data_used, 9.5, 10.5)\n",
    "                X_tr_extracted[num_con, per_idx, num_win, :] = data_filtered\n",
    "                \n",
    "                #PSD extraction\n",
    "                win_point = win_len * smp_freq\n",
    "                freqs, psd = scipy.signal.welch(data_used, smp_freq, nperseg = win_point)\n",
    "#                 magnitude = np.abs(psd)[np.where((freqs >= 7.6) & (freqs <=7.7))]\n",
    "                magnitude = np.abs(psd)[np.where((freqs == 10))]\n",
    "                X_tr_FFT_extracted[num_con, per_idx, num_win] = magnitude\n",
    "\n",
    "print(\"Done!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tr_extracted.shape)\n",
    "print(X_tr_FFT_extracted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Extracted_timeseries_win3.npy\", X_tr_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"PSD_amplitudes_win3.npy\", X_tr_FFT_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"CCA_after_extrated_psd.npy\", CCA_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
